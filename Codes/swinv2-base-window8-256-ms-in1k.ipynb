{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.21"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11875067,"sourceType":"datasetVersion","datasetId":7463018}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport timm\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport pandas as pd\nimport seaborn as sns\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom torch import nn, optim\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom timm.data import resolve_model_data_config\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CFG = {\n    # give corresponding model name from model finder given at the end of the notebook\n    'model_name': 'swinv2_base_window8_256.ms_in1k',\n    # give your corresponding batch size\n    'batch_size': 32,\n    # give corresponding epoch number\n    'epochs': 50,\n    # give appropriate learning rate\n    'learning_rate': 1e-5,\n    # num of workers from 0-4\n    'num_workers': 2,\n    # seed for reproducibility\n    'seed': 42,\n    # adjust your training directory\n    'train_directory': '/kaggle/input/insulator-images/Insulator images/Dataset/train',\n    # adjust your validation directory\n    'val_directory': '/kaggle/input/insulator-images/Insulator images/Dataset/validation',\n    # adjust your test directory\n    'test_directory': '/kaggle/input/insulator-images/Insulator images/Dataset/test',\n    'save_path': './model_checkpoints',\n    'results_dir': './results'\n}\nos.makedirs(CFG['save_path'], exist_ok=True)\nos.makedirs(CFG['results_dir'], exist_ok=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(CFG['seed'])\n\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_config = resolve_model_data_config(CFG['model_name'])\nprint(\"\\n\",data_config)\n\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from timm.data import resolve_model_data_config\nfrom torchvision import transforms\n\n# Model + Data Transforms\n# ----------------------------\ndef get_model(model_name, num_classes, device=torch.device(\"cpu\")):\n    model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n    return model.to(device)\n\n\n\ndef get_data_transforms(model, is_training=False):\n    data_config = resolve_model_data_config(model)\n    #print(\"\\n\",data_config)\n    input_size = data_config.get('input_size', (3, 224, 224))[1:]\n    mean = data_config.get('mean', (0.485, 0.456, 0.406))\n    std = data_config.get('std', (0.229, 0.224, 0.225))\n\n    print(f\"\\n[INFO] Creating {'training' if is_training else 'validation/testing'} transform\")\n    print(f\"[INFO] Using input size: {input_size}, mean: {mean}, std: {std}\")\n\n    transform_list = []\n    if is_training:\n        transform_list += [\n            transforms.RandomResizedCrop(input_size),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandAugment(num_ops=2, magnitude=9)\n        ]\n    else:\n        transform_list += [\n            transforms.Resize([int(x / 0.95) for x in input_size]),\n            transforms.CenterCrop(input_size)\n        ]\n\n    transform_list += [\n        transforms.ToTensor(),\n        transforms.Normalize(mean=mean, std=std)\n    ]\n\n    return transforms.Compose(transform_list)\n\n\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import datasets\nfrom torch.utils.data import DataLoader\n\n# ----------------------------\n# Data Loaders\n# ----------------------------\n\ndef prepare_dataloader(directory, model, batch_size, is_training):\n    transform = get_data_transforms(model, is_training=is_training)\n    dataset = datasets.ImageFolder(directory, transform=transform)\n\n    if is_training:\n        # Ensures reproducible shuffling in training\n        generator = torch.Generator()\n        generator.manual_seed(CFG['seed'])\n        loader = DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=True,\n            num_workers=CFG['num_workers'],\n            pin_memory=True,\n            generator=generator\n        )\n    else:\n        loader = DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=CFG['num_workers'],\n            pin_memory=True\n        )\n\n    return loader, dataset.classes\n\n\ndef get_dataloaders():\n    # Temporary model for transform config\n    temp_model = get_model(CFG['model_name'], num_classes=1, device=device)\n    \n    # Load training data once to get class names\n    train_loader, class_names = prepare_dataloader(\n        CFG['train_directory'], temp_model, CFG['batch_size'], is_training=True\n    )\n\n    # Redefine model with correct num_classes\n    num_classes = len(class_names)\n    model = get_model(CFG['model_name'], num_classes, device)\n\n    # Use the final model for val/test dataloaders\n    val_loader, _ = prepare_dataloader(\n        CFG['val_directory'], model, CFG['batch_size'], is_training=False)\n    test_loader, _ = prepare_dataloader(\n        CFG['test_directory'], model, CFG['batch_size'], is_training=False)\n\n    return train_loader, val_loader, test_loader, class_names\n\n\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    total_loss, correct = 0.0, 0\n    for images, labels in tqdm(loader, desc=\"Training\"):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * images.size(0)\n        correct += (outputs.argmax(dim=1) == labels).sum().item()\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n\ndef validate(model, loader, criterion, device):\n    model.eval()\n    total_loss, correct = 0.0, 0\n    with torch.no_grad():\n        for images, labels in tqdm(loader, desc=\"Validation\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item() * images.size(0)\n            correct += (outputs.argmax(dim=1) == labels).sum().item()\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n\n\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef run_training():\n    train_loader, val_loader, test_loader, class_names = get_dataloaders()\n    model = get_model(CFG['model_name'], len(class_names), device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=CFG['learning_rate'])\n\n    train_losses, val_losses = [], []\n    train_accuracies, val_accuracies = [], []\n\n    best_val_acc = 0.0\n    best_model_state = None\n\n    for epoch in range(1, CFG['epochs'] + 1):\n        print(f\"\\nEpoch {epoch}/{CFG['epochs']}\")\n        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = validate(model, val_loader, criterion, device)\n\n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n        print(f\"Val   Loss: {val_loss:.4f}, Val   Acc: {val_acc:.4f}\")\n\n        # Save best model based on validation accuracy\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = {\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n            }\n            best_path = os.path.join(CFG['save_path'], f\"best_model__{CFG['model_name']}.pt\")\n            torch.save(best_model_state, best_path)\n            print(f\"[✔] Best model updated and saved at epoch {epoch} -> {best_path}\")\n\n        # Record metrics\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        train_accuracies.append(train_acc)\n        val_accuracies.append(val_acc)\n\n    # Save last epoch model\n    last_model_state = {\n        'epoch': CFG['epochs'],\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n    }\n    last_path = os.path.join(CFG['save_path'], f\"last_model_epoch_{CFG['epochs']}__{CFG['model_name']}.pt\")\n    torch.save(last_model_state, last_path)\n    print(f\"[✔] Last epoch model saved at: {last_path}\")\n\n    # Plot and save metrics\n    plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies)\n\n    # Save training log to Excel\n    metrics_df = pd.DataFrame({\n        'Epoch': list(range(1, CFG['epochs'] + 1)),\n        'Train Loss': train_losses,\n        'Val Loss': val_losses,\n        'Train Accuracy': train_accuracies,\n        'Val Accuracy': val_accuracies\n    })\n\n    log_path = os.path.join(CFG['results_dir'], f\"epoch_metrics_{CFG['model_name']}.xlsx\")\n    metrics_df.to_excel(log_path, index=False)\n    print(f\"[✔] Training log saved to: {log_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies):\n    epochs = list(range(1, len(train_losses) + 1))\n\n    # A base width plus an increment for each epoch.\n    # You can tune these values for better visual results.\n    base_width = 8 # inches\n    width_per_epoch = 0.4 # inches per epoch\n    dynamic_width = max(base_width, len(epochs) * width_per_epoch)\n\n    # Loss Plot\n    plt.figure(figsize=(dynamic_width, 6)) # Height is fixed at 6 inches, width is dynamic\n    plt.plot(epochs, train_losses, 'bo-', label='Train Loss')  # blue circle markers\n    plt.plot(epochs, val_losses, 'rs-', label='Val Loss')      # red square markers\n    plt.xticks(epochs)  # Force integer ticks on x-axis\n    plt.title('Loss over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid()\n    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n    plt.savefig(os.path.join(CFG['results_dir'], f\"loss_curve_{CFG['model_name']}.png\"))\n    plt.show()\n    plt.close()\n\n    # Accuracy Plot\n    plt.figure(figsize=(dynamic_width, 6)) # Apply the same dynamic width\n    plt.plot(epochs, train_accuracies, 'g^-', label='Train Acc')  # green triangle markers\n    plt.plot(epochs, val_accuracies, 'md-', label='Val Acc')      # magenta diamond markers\n    plt.xticks(epochs)  # Force integer ticks on x-axis\n    plt.title('Accuracy over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid()\n    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n    plt.savefig(os.path.join(CFG['results_dir'], f\"accuracy_curve_{CFG['model_name']}.png\"))\n    plt.show()\n    plt.close()\n\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_model(model_name, num_classes, epoch, path):\n    model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n    checkpoint = torch.load(f\"{path}/model_epoch_{epoch}__{CFG['model_name']}.pt\", map_location='cpu',weights_only=True)\n    model.load_state_dict(checkpoint['model_state_dict'])  # ✅ only load the weights\n    model.eval()\n    return model\n\n\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport warnings  # Just use warnings\nfrom sklearn.metrics import classification_report\n\n# Ignore UndefinedMetricWarning\nwarnings.filterwarnings(\"ignore\", category=UserWarning)  # Filter UserWarnings in general\n\ndef plot_confusion_matrix(conf_matrix, class_names, model_name, save_dir='./results'):\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    \n    # Save figure\n    os.makedirs(save_dir, exist_ok=True)\n    save_path = os.path.join(save_dir, f\"confusion_matrix_{model_name}.png\")\n    plt.savefig(save_path)\n    print(f\"Confusion matrix saved to: {save_path}\")\n    \n    plt.show()\n    plt.close()\n\n\ndef evaluate_and_save(model, dataloader, class_names, save_dir):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    all_preds = []\n    all_labels = []\n   \n    model.to(device)\n\n    with torch.no_grad():\n        for imgs, labels in dataloader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            preds = torch.argmax(outputs, dim=1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Metrics\n    acc = accuracy_score(all_labels, all_preds)\n    \n    # Using zero_division=1 to handle undefined metrics\n    report = classification_report(all_labels, all_preds, target_names=class_names, digits=5, output_dict=True, zero_division=1)\n\n    conf_matrix = confusion_matrix(all_labels, all_preds)\n\n    print(f\"\\n Test Accuracy: {acc:.4f}\\n\")\n    print(\"Classification Report:\\n\", classification_report(all_labels, all_preds, digits=5, target_names=class_names))\n    print(\"Confusion Matrix:\\n\", conf_matrix)\n\n    # Plot Confusion Matrix\n    plot_confusion_matrix(conf_matrix, class_names, CFG['model_name'], save_dir)\n\n\n    # Save to Excel\n    os.makedirs(save_dir, exist_ok=True)\n    report_df = pd.DataFrame(report).transpose()\n    conf_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n\n    with pd.ExcelWriter(f\"{save_dir}/Test_Metrics_{CFG['model_name']}.xlsx\") as writer:\n        report_df.to_excel(writer, sheet_name='Classification_Report')\n        conf_df.to_excel(writer, sheet_name='Confusion_Matrix')\n\n    print(f\"\\nResults saved to: {save_dir}/test_metrics.xlsx\")\n\n    return acc, report_df, conf_df\n    \n\nprint(\"Section runs successfully\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"run_training()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataloaders\ntrain_loader, val_loader, test_loader, class_names = get_dataloaders()\n\n# --------- Evaluate Best Model ---------\nbest_model_path = os.path.join(CFG['save_path'], f\"best_model__{CFG['model_name']}.pt\")\nbest_model = get_model(CFG['model_name'], len(class_names), device)\ncheckpoint = torch.load(best_model_path, map_location=device)\nbest_model.load_state_dict(checkpoint['model_state_dict'])\n\nprint(\"\\n[🔍] Evaluating Best Model...\")\nacc_best, report_best, conf_best = evaluate_and_save(best_model, test_loader, class_names, save_dir='./results/best_model')\nprint(f\"[🏆] Best Model Testing Accuracy: {acc_best:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --------- Evaluate Last Model ---------\nlast_model_path = os.path.join(CFG['save_path'], f\"last_model_epoch_{CFG['epochs']}__{CFG['model_name']}.pt\")\nlast_model = get_model(CFG['model_name'], len(class_names), device)\ncheckpoint = torch.load(last_model_path, map_location=device)\nlast_model.load_state_dict(checkpoint['model_state_dict'])\n\nprint(\"\\n[🔍] Evaluating Last Epoch Model...\")\nacc_last, report_last, conf_last = evaluate_and_save(last_model, test_loader, class_names, save_dir='./results/last_model')\nprint(f\"[📦] Last Epoch Model Testing Accuracy: {acc_last:.4f}\")\n\nprint(\"✅ Section ran successfully.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"avail_pretrained_models = timm.list_models('*swin*',pretrained=True)\nprint(len(avail_pretrained_models))\navail_pretrained_models","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}